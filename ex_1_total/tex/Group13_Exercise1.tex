\documentclass{article}

\usepackage{epsfig}
\usepackage[mathscr]{eucal}
\usepackage{amsfonts}
\usepackage{amscd}
\usepackage{amsmath}
\usepackage{array}
\usepackage{amssymb}
%\usepackage[backend=bibtex8, sorting=none]{biblatex}
\usepackage{colordvi}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage[footnotesize]{caption}
\usepackage{fancyhdr}
\usepackage{pdfpages}
\usepackage{slashed}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{array}
\usepackage{caption}
\usepackage{subcaption}

%\usepackage{relsize}
\usepackage{color}
\usepackage{rotating}

\usepackage{slashed}

\usepackage{epsfig,amsmath,graphicx,amssymb,listings,slashed}
\usepackage[colorlinks,citecolor=blue,urlcolor=blue,linkcolor=blue]{hyperref}
\usepackage[outercaption]{sidecap}

\usepackage{booktabs}

%\smartqed
%\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{epsfig,amsmath,graphicx,amssymb,listings,slashed}
\usepackage[colorlinks,citecolor=blue,urlcolor=blue,linkcolor=blue]{hyperref}

\setlength{\evensidemargin}{0cm}
\setlength{\oddsidemargin}{0cm}
\setlength{\topmargin}{0.00cm}
\setlength{\textwidth}{16.0cm}
\setlength{\textheight}{24.00cm}
\setlength{\headheight}{0cm}
\setlength{\headsep}{0cm}
\setlength{\voffset}{0cm}
\setlength{\paperheight}{29cm}

\definecolor{ourbrown}{RGB}{155,100,15}
\definecolor{ourcyan}{RGB}{20,165,165}
\definecolor{ourpurple}{RGB}{145,0,140}
\definecolor{darkorange}{RGB}{225,100,0}
\definecolor{darkgreen}{RGB}{0,170,0}
\definecolor{darkgray}{RGB}{80,80,80}

\setlength{\marginparwidth}{20mm}

%\bibliography{literature.bib}





\begin{document}

\title{ Machine Learning - SS 2021 \\ Exercise 1: Classification }


	\author{Federico Ambrogi, \textcolor{blue} {e1449911@student.tuwien.ac.at } \\
	Adam HÃ¶fler, \textcolor{blue} {e11847620@student.tuwien.ac.at } \\
	Matteo Panzeri \textcolor{blue}{12039996@student.tuwien.ac.at } \\
    TU Wien }


%\ead{federico.ambrogi@univie.ac.at}




\maketitle
\setcounter{tocdepth}{2}
\tableofcontents

\section{Introduction}
In this document we describe the results of the implementation of three algorithms to solve classification problems on four different dataset.




\subsection{Data Sets Description}
Here we briefly introduce our four datasets.

\paragraph{Drug consumption data set} This is the data set taken from exercise 0, so here we only provide basic details. The primary task of our implementation is to classify the likeliness of the frequency of usage of a certain type of drug (from never used to current usage), given personal aspects such as gender, ethnicity, education background etc. and psychological traits.
In detail:
\begin{itemize}
	\item  \textbf{attributes}: 'age', 'gender', 'education', 'ethnicity', 'Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS' \\
	\item  \textbf{targets}: 'alcohol', 'amphetamines', 'amylNitrite', 'benzodiazepine', 'caffeine', 'cannabis', 'chocolate', 'cocaine', 'crack', 'ecstasy', 'heroin', 'ketamine', 'legal', 'LSD',
	'methadone', 'mushrooms', 'nicotine', 'volatileSubstance'
	divided in \textbf{7 classes}: "Never", ">10 Years Ago", "Last Decade", "Last Year", "Last Month", "Last Week", "Last Day"
\end{itemize}


\paragraph{Asteroids data set}
The asteroids data set is designed to perform a binary classification task. It consists of a total of astrophysical data, such as the distance from the Earth, the size of the major axis of the orbits, their mass etc. as well metadata regarding their name. The target feature for classification is a string variable that maps to boolean values "True" in the case the asteroid represents a concrete hazard for the Earth i.e. with high risk of impact, and "False" otherwise.

In detail:
\begin{itemize}
	\item  \textbf{attributes}:'Absolute Magnitude', 'Est Dia in KM(min)', 'Est Dia in KM(max)', 'Relative Velocity km per sec', 'Miss Dist.(kilometers)', 'Minimum Orbit Intersection', 'Jupiter Tisserand Invariant', 'Eccentricity', 'Semi Major Axis', 'Inclination', 'Asc Node Longitude', 'Orbital Period', 'Perihelion   Distance', 'Perihelion Arg', 'Aphelion Dist', 'Perihelion Time', 'Mean Anomaly', 'Mean Motion' \\


	\item  \textbf{target}: 'Hazardous' divided in \textbf{classes}: "True" and "False" \\
\end{itemize}


\paragraph{Breast Cancer (Kaggle Data Set)}
ccc

\begin{itemize}
	\item  \textbf{attributes}: 'radiusMean', 'textureMean', 'perimeterMean', 'areaMean',
	'smoothnessMean', 'compactnessMean', 'concavityMean',
	'concavePointsMean', 'symmetryMean', 'fractalDimensionMean',
	'radiusStdErr', ' textureStdErr' ,'perimeterStdErr' ,'areaStdErr',
	'smoothnessStdErr', 'compactnessStdErr', 'concavityStdErr',
	'concavePointsStdErr' ,'symmetryStdErr' ,'fractalDimensionStdErr',
	'radiusWorst', 'textureWorst' ,'perimeterWorst' ,'areaWorst',
	'smoothnessWorst' ,'compactnessWorst' ,'concavityWorst',
	'concavePointsWorst', 'symmetryWorst', 'fractalDimensionWorst' \\

	\item  \textbf{target}: 'class' divided in \textbf{classes}: "True" and "False" \\
\end{itemize}

\paragraph{Advertising Bidding (Kaggle Data Set)}

In detail:
\begin{itemize}
	\item  \textbf{attributes}: 'Region', 'City', 'AdExchange', 'Adslotwidth', 'Adslotheight', 'Adslotfloorprice',
	'CreativeID', 'Biddingprice', 'AdvertiserID', 'interest\_news', 'eduation', 'automobile','interest\_realestate', 'IT', 'electronicgame','interest\_fashion', 'entertainment', 'luxury','homeandlifestyle', 'interest\_health', 'food','interest\_divine', 'interest\_motherhood\_parenting', 'sports','interest\_travel\_outdoors', 'interest\_social', 'Inmarket\_3cproduct','Inmarket\_appliances', 'Inmarket\_clothing\_shoes\_bags' ,

	'Inmarket\_Beauty\_PersonalCare', 'Inmarket\_infant\_momproducts',
	'Inmarket\_sportsitem', 'Inmarket\_outdoor', 'Inmarket\_healthcareproducts',
	'Inmarket\_luxury', 'Inmarket\_realestate',

	'Inmarket\_automobile',
	'Inmarket\_finance', 'Inmarket\_travel', 'Inmarket\_education',
	'Inmarket\_service', 'art\_photography\_design',
	'onlineliterature', 'Inmarket\_electronicgame', '3c',
	'Inmarket\_book', 'Inmarket\_medicine', 'Inmarket\_fooddrink',
	'culture', 'sex',
	'Demographic\_gender\_male',

	'Demographic\_gender\_famale', 'Inmarket\_homeimprovement', 'Payingprice',
	'imp', 'click', 'Browser', 'Adslotvisibility', 'Adslotformat' \\

	\item  \textbf{target}: 'conv' divided in \textbf{classes}: "True" and "False"
\end{itemize}

In detail:
\begin{itemize}
	\item  \textbf{attributes}:'Absolute Magnitude', 'Est Dia in KM(min)', 'Est Dia in KM(max)', 'Relative Velocity km per sec', 'Miss Dist.(kilometers)', 'Minimum Orbit Intersection', 'Jupiter Tisserand Invariant', 'Eccentricity', 'Semi Major Axis', 'Inclination', 'Asc Node Longitude', 'Orbital Period', 'Perihelion   Distance', 'Perihelion Arg', 'Aphelion Dist', 'Perihelion Time', 'Mean Anomaly', 'Mean Motion' \\

	\item  \textbf{target}: 'Hazardous' divided in \textbf{classes}: "True" and "False"
\end{itemize}

\subsection{Framework and Implementation}
We implemented our analysis using the \textbf{python3.8} language, with its library for machine learning application \textit{scikit-learn} as well as \textit{numpy} and \textit{pandas} for data statistical analysis and data manipulation. In the attached package, two distinct files can be found: the first, called \textit{data\_preparation.py}, cleans and standardizes the input data set, so that they are ready for data processing. The main script for the data analysis is called \textit{classifier.py}. This code will run the different classifiers on the data sets, and will produce the comparison data and plots that will be found in this report.



\subsection{Workflow}
Without giving particular details on the implementations of the various classifier, which can be read inside the scripts, we summarize here how the workflow is constructed, as well as how the classification tasks have been implemented.
First, the cleaned data (i.e. processed by \textit{data\_preparation.py} ) are imported as \textit{pandas} data frame. For each data set, a dictionary provided the list of names of features that will be used to predict the target feature. Then, we analyse the class balancing of the predicting features; it is possible to decide to apply a balancing procedure before processing further(see Section \ref{sec:balance} for details). The data can now be trained: the splitting of the data into a training and testing set is done differently depending on the chosen methods between "hold out" (by the $model_selection.train_test_split$)  or "kNN-cross validation" (by the $ XXX$); see Section \ref{sec:cross}.
At this point, the classification algorithms are applied to the training and testing sets. The following algorithms have been chosen.

\paragraph{Decision Three} We use the \textit{DecisionTreeClassifier} module, where we try two implementation of the "Gini" and "entropy" (parameter $criterion$) criteria for the Gini impurity and for the information gain,respectively, to measure the quality of a split.

\paragraph{kNN - k Nearest Neighbours} We use the \textit{KNeighborsClassifier} module, where we vary the number of neighbours (parameter $n_neighbors$) in the set $[5,10,50]$.

\paragraph{naive Bayes}  We use the \textit{GaussianNB} module, with default parameters.



\section{Data Exploration and Pre-processing}
In this section we describe the necessary preliminary steps to import and prepare the data to make them suitable for the learning algorithms.
The steps are handled by the script \textit{data\_preparation.py} which includes dedicated function to pre-process each data set.

\paragraph{Drug consumption}
Since this dataset was already preprocessed (transformation of the nominal features) and cleaned of missing values or outliers by the providers of the dataset \cite{fehrman2017factor}, the data preparation is not given. As can be seen in Fig.\ref{fig:imbalance} we deal with heavily imbalanced data. Normally, the approach would be to resample the data (see Sec.\ref{sec:balance}) but with our later on discussed approach we would run into problems due to low statistics - we decided to keep the dataset as it is.

As can be seen in Fig.\ref{fig:imbalance} the majority of the drugs can be grouped by their imbalance towards either CL0 ("Never used") or CL6 ("Last day") - those two groups give a rough representation of "everyday drugs" like chocolate and "marginal drugs" like heroin. Since the total number of respondents is constant, a vast majority of one class implies a small occurrence of the other classes and equalizing the samples results in low statistics and no usable outcome of the classification - this was the result of our tests. \\

\subsection{Asteroids Data Set}
The original data set contained 40 columns of different variable types (numeric and categorical). However, some columns were unnecessary, not usable or redundant for classification purposes, or contained constant values.


\subsection{Advertising Bidding (Kaggle Data Set)}
In the dataset we have both nominal and ordinal data.
An example of nominal attribute is the Browser where is specified the browser used by the user in that observation.
An example of ordinal data is the "Inmarket\_realestate" which indicates the tendency of an user to bid (1) or not to bid (0) on a real estate. In this dataset there are 12500 observations and 65 attributes.
In the dataset there are missing values in particular the $4\%$ of the rows has the URL attribute missing and the 38% of the rows has of the UserID missing.
This dataset is characterized by the presence of several attributes with low information, for example the attribute "Inmarket\_sportsitem" has $98\%$ of the observations with value 1(yes)  or the attribute "Inmarket\_outdoor" with the percentage above the $99\%$,

 this is solved thanks at the balancing process that we will perform before splitting the dataset.

The following columns have been removed under the assumption that they depends only on the single observation and consequently generate noise without bringing additional information.
the columns are: "RowID", "UserID", "BidID", "IP" , "Domain", "URL", "Time\_Bid", "AdslotID".
In the dataset the columns "Browser", "Adslotvisibility' , "Adslotformat" have been converted using a label encoder.


\subsection{Breast Cancer (Kaggle Data Set)}
In this dataset every attribute is a measurement done during a medical exam.
The attributes are all numerical.
Examples of the attributes are: "concavePointsMean", "symmetryMean","fractalDimensionMean", "radiusStdErr", "textureStdErr".
There are no missing values and we did not preprocesse any attribute. Due the domain of the attributes there are no low information columns so we have used them all in order to fit the classifiers.



\section{Performance Tests}
\subsection{Model Training Parameters}
We remind here the definition of the metric parameters we will used to quantify the performance of our classifiers i.e. precision ($P$), recall ($R$) and accuracy ($A$):
\\

\begin{equation}
P = \frac{TP}{TP + FP} \ \ \ \ \ \ \ \  R = \frac{TP}{TP + FN} \ \ \ \ \ \ \ \  A = \frac{TP + TN}{\#all}
\end{equation}
\\

It is straightforward to calculate these parameters for binary classification tasks out of the confusion matrix. In case of multiple labels, we need to calculate these parameter for each class, given that:
\begin{itemize}
	\item  $TPs$ are the values in the diagonal; \
	\item  $FNs$ for a certain class are the sum of values in the corresponding row excluding the $TP$; \
	\item  $FPs$ for a certain class are the sum of values in the corresponding column excluding the $TP$; \
	\item  $TNs$ for a certain class are the sum of all rows and columns, excluding the class's column and row. \
\end{itemize}


Another convenient metric, particularly because it is calculated directly from the proper \textit{scikit-learn} function, is called $f1-score$, which is defined as the harmonic mean of the precision and recall:
\begin{equation}
f1-score = 2 \times \frac{P \dot R }{P + R }
\end{equation}


\subsection{Confusion Matrix}
For each classifier, we produce a confusion matrix where each entry $i,j$ corresponds to the number of observations in group $i$, but predicted to be in group $j$. We chose to normalize the entries according to the sum of each row.
In case of binary classification, the matrix reduces to the number of true negatives ($TN$), false positives ($FP$), false negatives ($FN$) and true positives ($TP$).

Examples can be see in Fig. \ref{confusion_matrices}.





\begin{figure}[h!]
	\centering
	\begin{minipage}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{Plots/m2.png}

	\end{minipage}
	\begin{minipage}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{Plots/m1.png}

	\end{minipage}

	\caption{Example confusion matrices for {\color{red} REDO, just an example }  }
	\label{confusion_matrices}
\end{figure}


{\color{red} Describe micro averaging and macro averaging, will we report both ? }


\subsection{Holdout and Cross Validation}\label{sec:cross}
Here we describe briefly the techniques of "holdout" and "cross validation" that are used to evaluate a model. The \textbf{holdout} method is essentially based on the splitting on the input data set into two subset, one used for training the model, and one used for testing the model, for example in $80\%-20\%$ proportion, although there is not fix recipe for this split. Once the model is trained, the evaluation can be performed on the test data set, and this is therefore possible to check if the prediction of the model match the data. One big issue of this model is that the training strongly depend on the splitting of the initial data set, for example if the characteristic of the training data set are not representative of the whole data set.

A more powerful method is the \textbf{cross-validation} or "k-fold cross validation". Form the full dataset, a test is held out for final evaluation, but the validation set is no longer needed. For this, the training set is split into $k$ sets, so that the model is trained using $k-1$ folds as training data, and the remaining one is used for the validation as a test set (to compute the interesting metric of the model).
Once we obtain such $k$ number of metrics, the final result is the average of these parameters, obtained for each iteration of the cross-validation on each distinct fold.

\subsection{Class Balance}\label{sec:balance}
In this section we discuss the problem of imbalanced data. Whenever classes are not represented equally (imbalanced data), the result of the training and testing of the model might be biased. In particular, a metric such the accuracy might appear very satisfying while, in fact, it is only representing the underlying class distribution. The model in in fact favoured to learn the class with the majority of instances.

Fig. \ref{fig:imbalance} shows the distribution of the various class attributes for our datasets. Starting with the binary classification problems we see that the "breast cancer" dataset is slightly imbalanced
($37,5\%$- $62,5\%$) recurrence events vs non recurrence, while the imbalance is more pronounced for the other dataset, in particular we see
($17\%$-$83\%$) hazardous vs non hazardous, and ($2\%$-$98\%$) buy vs  non buy classes.

In the case of the drug consumption dataset, the situation it is more complicated to analyse since it varies largely depending on the considered drug.

\begin{figure}[h!]
	\centering
	\begin{minipage}[b]{0.99\textwidth}
		\includegraphics[width=\textwidth]{Plots/Inbalance_drugs.png}
	\end{minipage}
	\begin{minipage}[b]{0.32\textwidth}
	\includegraphics[width=\textwidth]{Plots/Inbalance_asteroids.png}
	\end{minipage}
	\begin{minipage}[b]{0.32\textwidth}
	\includegraphics[width=\textwidth]{Plots/Inbalance_breastCancer.png}
	\end{minipage}
	\begin{minipage}[b]{0.32\textwidth}
	\includegraphics[width=\textwidth]{Plots/Inbalance_advertisingBidding.png}
    \end{minipage}
	\caption{Distribution of classes for the target attributes for the multiclass classification (top panel, drug dataset) and binary classification (bottom panel, asteroids, breast cancer and advertising bidding datasets).}
	\label{fig:imbalance}
\end{figure}

In order to balance the dataset, we implemented and algorithm that performs the following steps.
First, it extracts the number of entries in the under-represented class (which by chance is always class "True" for the three binary classification tasks). Then we randomly select a number of rows from the remaining data of where class is equal to "False", adding an extra $10\%$ to this total. Then, we create a final dataset combining the rows with the class "True" and the randomly selected "False".
This step is done at a preliminary phase before any splitting into the training and testing subsets.




\section{Comparison}

\subsection{Drug consumption}

Overall the performance of the classification is not well. Looking at the confusion matrices we can see the expected influence of the datas imbalance. The overall fitting strategy is towards the most dominant class whereas the decision tree seems to be the most resistant against this bias (looking at the distribution around the main diagonal).

\begin{figure}[h!]
	\centering
	\begin{minipage}[b]{0.32\textwidth}
		\includegraphics[width=\textwidth]{Plots/alcohol_DecisionTree_entropy.png}
	\end{minipage}
	\begin{minipage}[b]{0.32\textwidth}
		\includegraphics[width=\textwidth]{Plots/alcohol_DecisionTree_gini.png}
	\end{minipage}
	\begin{minipage}[b]{0.32\textwidth}
		\includegraphics[width=\textwidth]{Plots/alcohol_GaussianNB_naiveB.png}
	\end{minipage}
	\begin{minipage}[b]{0.32\textwidth}
		\includegraphics[width=\textwidth]{Plots/alcohol_KNeighbors_5.png}
  \end{minipage}
	\begin{minipage}[b]{0.32\textwidth}
		\includegraphics[width=\textwidth]{Plots/alcohol_KNeighbors_10.png}
  \end{minipage}
	\begin{minipage}[b]{0.32\textwidth}
		\includegraphics[width=\textwidth]{Plots/alcohol_KNeighbors_50.png}
  \end{minipage}
	\caption{Confusion matrices for the used classifiers on the drug cocaine.}
	\label{fig:conf_matr_cocaine}
\end{figure}




\paragraph{Decision Tree}



\clearpage
\bibliography{literature.bib}{}
\bibliographystyle{unsrt}

\end{document}

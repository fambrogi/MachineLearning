Data Sources:

https://www.kaggle.com/kumarajarshi/life-expectancy-who
https://www.kaggle.com/aungpyaeap/fish-market
https://www.kaggle.com/janiobachmann/math-students

https://www.kaggle.com/synergystud/a-fine-windy-day-hackerearth-ml-challenge

The principle behind the algorithm is this:
The split is computed on the attribute that has the biggest standard deviation reduction
I compute it on every attribute in the dataset.
In order to get it consider An attribute at a time and split the dataset according to the average value of the elements
in the attribute column.
 the steps are:
 - for every attribute:
    -compute the avg of dataset[attribute]
    -split the dataset according to: dataset[attribute]<avg
    -on those splits compute the standard deviation of the split
 -I choose the split attribute according the biggest standard deviation reduction


From: https://www.youtube.com/watch?v=g9c66TUylZ4

1. set a minimum number of items per split e.g. 10? 20? to prevent overfitting
   I.e. if a possible leaf contains lees than this minimum number, I do not split further

2. for every attribute:
     - calculate RMS or RSS (residual sum squared)
       - find the split that minimizes the RSS
	 - this becomes the candidate split for the attirbute

3. compare the RSS that minimize the RSS of each attribute:
   - the final choice for the root is the split of the attribute chosen among all, that minimizes the RSS.

4. This fixes the root number 1

5. repeat again until all nodes are leaves i.e. cant be split anymore due to low number of items inside 
